{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mat4py import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # or if you want more than 1 GPU set it as \"0\", \"1\"\n",
    "import tensorflow\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import sklearn\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization,Concatenate,concatenate, Input\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling1D\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "#from tensorflow.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string=['ucddb002','ucddb003'\\\n",
    "             ]#'ucddb008','ucddb011','ucddb013','ucddb014','ucddb010','ucddb012','ucddb014','ucddb015','ucddb017',\\'ucddb019','ucddb020','ucddb021','ucddb022','ucddb023','ucddb024',\\'ucddb025','ucddb026','ucddb027','ucddb028','ucddb005','ucddb006','ucddb007','ucddb009'\n",
    "\n",
    "\n",
    "valid_features=np.zeros((1,1408))\n",
    "test_features=np.zeros((1,1408))\n",
    "valid_labels=np.zeros((1,1))\n",
    "test_labels=np.zeros((1,1))\n",
    "for l in list_string:\n",
    "        \n",
    "        \n",
    "        ecg_valid = loadmat('C:\\\\Users\\\\vedan\\\\Downloads\\\\SLEEP APNEA\\\\selected\\\\'+l+'_ecg_valid.mat') #displaying data in a good way\n",
    "        ecg_valid = np.array(ecg_valid['ecg_valid'])\n",
    "        ecg_valid_labels=loadmat('C:\\\\Users\\\\vedan\\\\Downloads\\\\SLEEP APNEA\\\\selected\\\\'+l+'_valid_labels.mat')\n",
    "        ecg_valid_labels = np.array(ecg_valid_labels['class_valid'])\n",
    "        valid_features=np.append(valid_features,ecg_valid,axis=0)\n",
    "        valid_labels=np.append(valid_labels,ecg_valid_labels)\n",
    "       \n",
    "        \n",
    "        ecg_test = loadmat('C:\\\\Users\\\\vedan\\\\Downloads\\\\SLEEP APNEA\\\\selected\\\\'+l+'_ecg_test.mat')\n",
    "        ecg_test = np.array(ecg_test['ecg_test'])\n",
    "        ecg_test_labels=loadmat('C:\\\\Users\\\\vedan\\\\Downloads\\\\SLEEP APNEA\\\\selected\\\\'+l+'_test_labels.mat')\n",
    "        ecg_test_labels = np.array(ecg_test_labels['class_test'])\n",
    "        test_features=np.append(test_features,ecg_test,axis=0)\n",
    "        test_labels=np.append(test_labels,ecg_test_labels)\n",
    "        \n",
    "ecg_valid=valid_features[1:,:]\n",
    "#ecg_valid=np.expand_dims(ecg_valid, axis=2)\n",
    "valid_labels=valid_labels[1:]\n",
    "valid_labels = valid_labels.flatten()\n",
    "\n",
    "ecg_test=test_features[1:,:]\n",
    "#ecg_test=np.expand_dims(ecg_test, axis=2)\n",
    "test_labels=test_labels[1:]\n",
    "test_labels = test_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=np.zeros((1,1408))\n",
    "\n",
    "train_labels=np.zeros((1,1))\n",
    "\n",
    "for l in list_string:\n",
    "        ecg_train = loadmat('C:\\\\Users\\\\vedan\\\\Downloads\\\\SLEEP APNEA\\\\selected\\\\'+l+'_ecg_train.mat')\n",
    "        ecg_train = np.array(ecg_train['ecg_train'])\n",
    "        ecg_train_labels=loadmat('C:\\\\Users\\\\vedan\\\\Downloads\\\\SLEEP APNEA\\\\selected\\\\'+l+'_train_labels.mat')\n",
    "        ecg_train_labels = np.array(ecg_train_labels['class_train'])\n",
    "        train_features=np.append(train_features,ecg_train,axis=0)\n",
    "        train_labels=np.append(train_labels,ecg_train_labels)\n",
    "        \n",
    "ecg_train=train_features[1:,:]\n",
    "#ecg_train=np.expand_dims(ecg_train, axis=2)\n",
    "train_labels=train_labels[1:]\n",
    "train_labels = train_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train_mean=np.mean(ecg_train)\n",
    "ecg_train_std=np.std(ecg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ecg_train.shape[0]):\n",
    "    ecg_train[i,:]=(ecg_train[i,:]-ecg_train_mean)/ecg_train_std\n",
    "    \n",
    "for i in range(ecg_valid.shape[0]):\n",
    "    ecg_valid[i,:]=(ecg_valid[i,:]-ecg_train_mean)/ecg_train_std\n",
    "    \n",
    "for i in range(ecg_test.shape[0]):\n",
    "    ecg_test[i,:]=(ecg_test[i,:]-ecg_train_mean)/ecg_train_std\n",
    "\n",
    "ecg_train=np.expand_dims(ecg_train, axis=2)\n",
    "ecg_valid=np.expand_dims(ecg_valid, axis=2)\n",
    "ecg_test=np.expand_dims(ecg_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_labels\n",
    "y_valid=valid_labels\n",
    "y_test=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_train_num = y_train_encoder.fit_transform(y_train)\n",
    "y_train_wide = tensorflow.keras.utils.to_categorical(y_train_num, num_classes)\n",
    "\n",
    "y_valid_num = y_train_encoder.fit_transform(y_valid)\n",
    "y_valid_wide = tensorflow.keras.utils.to_categorical(y_valid_num, num_classes)\n",
    "\n",
    "y_test_num = y_train_encoder.fit_transform(y_test)\n",
    "y_test_wide = tensorflow.keras.utils.to_categorical(y_test_num, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(1408, 1))\n",
    "x = BatchNormalization()(input_layer)\n",
    "x = Conv1D(3, kernel_size=100, strides=2)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPooling1D(pool_size=2, strides=2)(x)\n",
    "x = Conv1D(50, 10)(x)\n",
    "x = MaxPooling1D(pool_size=2, strides=2)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "output_layer = Dense(2, activation='softmax', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "\n",
    "model_ecg = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_ecg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "model_ecg.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath_ecg = './best_weights_ecg_32layer.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_weights_filepath_ecg = './best_weights_ecg_32layer.hdf5'\n",
    "mcp_ecg = ModelCheckpoint(best_weights_filepath_ecg, monitor=\"val_accuracy\",\n",
    "                      save_best_only=True, save_weights_only=False)\n",
    "            \n",
    "history = model_ecg.fit(ecg_train, y_train_wide,\n",
    "         batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(ecg_valid, y_valid_wide),\n",
    "          callbacks=[mcp_ecg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(6,12))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "plt.xlabel('Epochs (100)')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::100])\n",
    "plt.title('Training and Validation Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(acc, 'green', label='Training Accuracy')\n",
    "plt.plot(val_acc, 'red', label='Validation Accuracy')\n",
    "plt.xticks(range(0,epochs)[0::100])\n",
    "plt.title('Training and Validation Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig(\"plots_perf.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ecg.load_weights('./best_weights_ecg_32layer.hdf5')\n",
    "y_pred = model_ecg.predict(ecg_test)\n",
    "predict_test=np.argmax(y_pred, axis=1)\n",
    "predict_test=predict_test.reshape(predict_test.shape[0],1)\n",
    "cm=confusion_matrix(y_test_num, predict_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
